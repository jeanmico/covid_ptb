---
title: "Air surface construction and analysis"
author: "Jean Costello"
date: "4/19/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE, warning=FALSE, libraries, echo=FALSE}

require(RColorBrewer); require(ggplot2)
require(mapdata); require(maptools)
library(raster)
#library(zipcode) 
library(choroplethr)
library(rgdal)
library(ggmap)
library(sp)
require("plyr"); require(dplyr)
library(tgp)
library(mgcv)
library(gstat)
library(automap)
library(raster) 
library(dismo)
library(reshape)
library(reshape2)
library(leaflet); library(rgeos)
library(leaflet.extras)
library(rgdal)
require(ggspatial)
library(mapview); library(webshot)
library(rasterVis)
library(sf)
library(tidyverse)
library(stringr)
library(viridis)
library(scico)
library(patchwork)
library(tmap)

# install.packages("ncdf4")
library(ncdf4)
```


## Air surface

```{r read files}
county_ref = read.csv('~/covid/california_county_dict.csv')
epa_raw = read.csv('~/covid/EPA_2020_pm25_CA.csv')
```

How many counties do not have an EPA sensor?
```{r}
epa_counties <- unique(epa_raw$COUNTY_CODE)
print(nrow(county_ref) - length(epa_counties))
```
Which counties do not have a sensor?
```{r counties with no sensors}
missing_fips <- setdiff(county_ref$county_fips, epa_counties)
counties_no_sensors = county_ref[county_ref$county_fips %in% missing_fips, ]
print(counties_no_sensors$county_name)
```

Pull in sensors for counties with none.
```{r}
#nearest_sensors <- read.csv('~/covid/county_sensors_nnjoin.csv')
distance_matrix <- read.csv('~/covid/distance_matrix.csv')
colnames(distance_matrix) <- c('county_fips', 'sensor_id', 'distance')
```

Where are these counties located?
```{r counties with no sensors map}


```

Which counties have multiple sensors?
```{r counties with multiple sensors}
sensor_locations <- epa_raw %>% 
  dplyr::select(Site.ID, Site.Name, CBSA_CODE, CBSA_NAME, STATE_CODE, STATE, COUNTY_CODE, COUNTY, SITE_LATITUDE, SITE_LONGITUDE) %>%
  distinct()

sensors_by_county <- sensor_locations %>%
  group_by(COUNTY_CODE) %>% dplyr::summarise(num_sensors = n())

# add number of EPA sensors to the county reference df
county_ref = merge(county_ref, sensors_by_county, by.x = 'county_fips', by.y = 'COUNTY_CODE', all.x = TRUE)
county_ref[is.na(county_ref)] <- 0
print(county_ref[county_ref$num_sensors > 1, c('county_name', 'num_sensors')]) # print the names and number of sensors in counties with more than 1
```
```{r sensors map}

```

In counties with multiple sensors, how well do they agree?

```{r read air surface}
pm25 <- raster("~/covid/V4NA03_PM25_NA_201801_201812-RH35.nc")
pmdat <- projectRaster(pm25, crs = "+proj=longlat +datum=WGS84")

```

```{r}
#empty_counties <- nearest_sensors %>% filter(COUNTYFP %in% counties_no_sensors$county_fips)

#add_counties <- merge( epa_raw, empty_counties, by.x = 'Site.ID' , by.y = 'HubName')

#add_counties <- add_counties %>% mutate(COUNTY_CODE = COUNTYFP, COUNTY = NAME) %>% dplyr::select(colnames(epa_raw))

#epa_raw <- rbind(epa_raw, add_counties)

```


```{r determine county multipliers}
epa_rast <- raster::extract(pmdat, SpatialPointsDataFrame(sensor_locations[c("SITE_LONGITUDE", 'SITE_LATITUDE')], 
                                                          data = sensor_locations['Site.ID']), df=TRUE)
epa_rast <- cbind(epa_rast, sensor_locations$Site.ID)
colnames(epa_rast) <- c('ID', 'PM2.5', 'Site.ID') #rename columns

epa <- merge(epa_raw, epa_rast, by='Site.ID', all.x = TRUE)

epa <- epa %>% mutate(multiplier = Daily.Mean.PM2.5.Concentration/PM2.5)

# if any Site.IDs are duplicated, select the lowest POC and discard the others 
#  delete this if we are only using POC == 1
epa_rmv <- epa %>% group_by(Site.ID, Date) %>% 
  dplyr::summarize(dup_count = n(), keep_POC = min(POC))

# remove rows where Site.ID = '' and POC = '')
epa  <- merge(epa, epa_rmv, by = c('Site.ID', 'Date'))
epa <- epa %>% filter(POC == keep_POC) %>% dplyr::select(-c('dup_count', 'keep_POC'))

# compute the average multiplier by county
county_mult <- epa %>% dplyr::group_by(COUNTY_CODE, Date) %>%
  dplyr::summarise(
    mean_mult = mean(multiplier), stdev_mult = sd(multiplier), num_measures = n())
```
How many days are we missing per county??
```{r}





```


```{r standard deviations plot}
#histograms of standard deviations (for multiple sensors within county)
sd_hist <- ggplot(filter(county_mult, num_measures>1), aes(x=stdev_mult)) +
  geom_histogram()  +
  scale_y_continuous(trans='log10') +
  ylab('Count') +
  xlab('Standard deviation of sensors within counties') +
  theme_minimal()
sd_hist
```

The range of standard deviations of sensors within counties is `r range(county_mult$stdev_mult, na.rm = TRUE)`.

How many multipliers are negative? `r nrow(county_mult[county_mult$mean_mult < 0, ])`

Read in a map of California counties, show number of sensors per county
```{r}
ca_county = rgdal::readOGR('/Users/student/covid/cb_2018_us_county_5m')
ca_county <- subset(ca_county, STATEFP == '06')
ca_county$county_int = as.integer(ca_county$COUNTYFP)
ca_county <- merge(ca_county, county_ref, by.x = 'county_int', by.y = 'county_fips')

mycolors = c('#D3D3D3', '#bae4b3','#74c476','#31a354','#006d2c')

county_map <- tm_shape(ca_county) + tm_polygons(col = 'num_sensors', breaks = c(0,1,2,6,10,14),
                                                palette = mycolors)


county_map
```
redo this map using POC == 1 to see how many sensors we retain

Also should map the sensors themselves here.

Map the 2018 surface.

```{r}
pm25_ca <- mask(pm25, ca_county)

rast_18 <- tm_shape(pm25_ca, bbox = ca_county) + tm_raster() +
  tm_shape(ca_county) + tm_polygons(alpha = 0) +
  tm_layout(legend.position = c('right', 'top'))

rast_18

```


Multiply each county.

```{r}

rastname_base = '/Volumes/Padlock/covid/rasts/'
rastname_img = '/Volumes/Padlock/covid/rast_imgs/'

# basic raster with extent
r<- raster(ncol = ncol(pm25_ca), nrow = nrow(pm25_ca))
extent(r) <- extent(ca_county)


# the more correct approach:
#   for each day, rasterize the shapefile; the value of each county is its multiplier
#   multiply the rasters
#   store each day as an output
datelist <- seq(as.Date('2020-01-01'), as.Date('2020-12-31'), by='days')
for (i in 1:length(datelist)) {
  print(paste(i, 'start', Sys.time()))
  datemult <- county_mult %>% filter(as.Date(Date, '%m/%d/%Y') == datelist[i])
  
  if (nrow(datemult) < 58) {
    # deal with counties without a sensor
    tmp_epa <- epa %>% filter(as.Date(Date, '%m/%d/%Y') == datelist[i])  # epa sensors available for the current date
    tmp_fips <- setdiff(county_ref$county_fips, datemult$COUNTY_CODE)  # what counties are we missing?
    
    tmp_dist <- distance_matrix %>% filter(county_fips %in% tmp_fips, sensor_id %in% tmp_epa$Site.ID) %>% 
      group_by(county_fips) %>%
      dplyr::summarise(nearest_epa = sensor_id[which.min(distance)])  # find the nearest sensor available
    
    if (nrow(tmp_dist) + nrow(datemult) != 58) {
      print(paste('No sensors for the counties:', setdiff(tmp_fips, tmp_dist$county_fips)))
    }

    tmp_add = merge(tmp_epa, tmp_dist, by.x = 'Site.ID' , by.y = 'nearest_epa')
    
    # reassign county, create and select necessary columns
    tmp_add <- tmp_add %>% mutate(COUNTY_CODE = county_fips, 
                                  mean_mult = multiplier, stdev_mult = 0, num_measures = 1) %>% 
      dplyr::select(COUNTY_CODE, Date, mean_mult, stdev_mult, num_measures)

    datemult <- rbind(datemult, tmp_add)  # add on values for the missing counties
  }

  county_full <- merge(ca_county, datemult, by.x = 'county_int', by.y = 'COUNTY_CODE')

  # make a raster of the county file, value set to county multiplier
  rast_mult <- rasterize(county_full, r, 'mean_mult')
  
  rs_rast_mult <- resample(rast_mult, pm25_ca)  # TODO: why is this so SLOW??

  # multiply the two rasters and save the output
  rast_date = rs_rast_mult * pm25_ca
  
    #rastname = paste(rast_basename, i, '.grd', sep = '_')
  #writeRaster(raster(tmprast), filename = rastname)
  
  rastname = paste(rastname_base, datelist[i], '.grd', sep = '')
  writeRaster(rast_date, filename = rastname)
  
  rastimg = paste(rastname_img, datelist[i], '.png', sep = '')
  
  rastplt = tm_shape(rast_date, bbox = ca_county) + tm_raster(title = 'PM2.5') +
  tm_shape(ca_county) + tm_polygons(alpha = 0) +
  tm_layout(title = datelist[i], title.position = c('right', 'top'),
    legend.position = c(.8, .6))
  
  tmap_save(rastplt, rastimg)
  
  print(paste(i, 'complete', Sys.time()))
}




```

Map the 2020-01-01 surface. Visually check to see that it makes sense.

```{r}


```

















